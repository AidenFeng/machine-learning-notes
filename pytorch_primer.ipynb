{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to PyTorch\n",
    "PyTorch is an open source deep learning library developed primarily by Facebook's AI Research lab. The two main flavors of PyTorch are:\n",
    "\n",
    "1. Tensor computing (like NumPy) with GPU support. This means we can treat a PyTorch tensor and a Numpy array as mostly identical.\n",
    "1. Deep neural networks built on a tape-based automatic differentiation system. This means the library has its own way of computing the gradients of complex functions, which we don't have to worry about.\n",
    "\n",
    "This primer will introduce you to some common API calls and functionalities of PyTorch. There are many excellent tutorials online, including one from the [official PyTorch page](http://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html), if you like to know more about the subject."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. PyTorch basics\n",
    "### 1.1. Creating a tensor\n",
    "The primary data structure used in PyTorch is a *tensor*, which stores data in a multi-dimensional matrix format, similar to a Numpy array (note that in mathmematics, *tensor* and *matrix* are two distinct concepts, but here we can treat them as identical). Here are the data types supported by PyTorch tensor:\n",
    "\n",
    "| Tensor Type  |  Data Type   |\n",
    "|--------------|--------------|\n",
    "| FloatTensor  | 32-bit float |\n",
    "| DoubleTensor | 64-bit float |\n",
    "| HalfTensor   | 16-bit float |\n",
    "| IntTensor    | 16-bit int   |\n",
    "| LongTensor   | 32-bit int   |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can pass any array-like object such as Python list or Numpy array to `torch.tensor()` or `torch.as_tensor()` to create a tensor project. The difference between these is that `torch.tensor` always copies the data, while `torch.as_tensor` always tries to avoid copying the data, especially when the input is already a Numpy array, i.e., changing the output of `torch.as_tensor` may change the original data source as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'> tensor([[1, 2],\n",
      "        [3, 4]]) torch.int64\n",
      "<class 'numpy.ndarray'> [[1 2]\n",
      " [3 4]] int64\n",
      "<class 'torch.Tensor'> tensor([[1, 2],\n",
      "        [3, 4]]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "W = torch.tensor([[1, 2], [3, 4]])\n",
    "a = np.array([[1, 2], [3, 4]])\n",
    "V = torch.as_tensor(a)\n",
    "print(type(W), W, W.dtype)\n",
    "print(type(a), a, a.dtype)\n",
    "print(type(V), V, V.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One important parameter to keep in mind is the `device` parameter, which specifies the type of device (CPU or GPU) that should hold the tensor object (or other objects such as a machine learning model). This allows you to control which operations are performed on CPU and which are on GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2.],\n",
       "        [3., 4.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "# create a tensor on a specified device\n",
    "v = torch.tensor([[1, 2], [3, 4]], device = device)\n",
    "\n",
    "# move the tensor to CPU, also change datatype to double\n",
    "v.to(\"cpu\", torch.double)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the output of `print(device)` will be `cpu` by default, but if you have a GPU set up, the output will `cuda` instead. The eaiest way to set up a GPU is uploading this notebook to Colab, then on the top toolbar select Runtime --> Change runtime type, and set \"Hardware accelerator\" to GPU (yes, Colab provides free GPU access!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conversion between Numpy array and Torch tensor can be done conveniently with `.numpy()` and `.from_numpy()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> [[1 2]\n",
      " [3 4]]\n",
      "<class 'torch.Tensor'> tensor([[1, 2],\n",
      "        [3, 4]])\n"
     ]
    }
   ],
   "source": [
    "torch_to_numpy = W.numpy()\n",
    "numpy_to_torch = torch.from_numpy(a)\n",
    "print(type(torch_to_numpy), torch_to_numpy)\n",
    "print(type(numpy_to_torch), numpy_to_torch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `torch.from_numpy` functions similarly to `torch.as_tensor`, in that the input Numpy array and output tensor share the same memory, and modifying one will change the other as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Operating on tensor\n",
    "PyTorch tensor also supports many matrix-based operations. In general, for large array sizes (e.g., $40000^2$ array elements), Numpy provides faster array initialization but slower element access and array operations than PyTorch (see [here](https://medium.com/python-pandemonium/how-pytorch-will-replace-numpy-2df48427f56d) for an example comparison)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6.  8.]\n",
      " [10. 12.]] \n",
      "\n",
      "tensor([[ 6.,  8.],\n",
      "        [10., 12.]], dtype=torch.float64)\n",
      "[[4. 4.]\n",
      " [4. 4.]] \n",
      "\n",
      "tensor([[4., 4.],\n",
      "        [4., 4.]], dtype=torch.float64)\n",
      "[[ 5. 12.]\n",
      " [21. 32.]] \n",
      "\n",
      "tensor([[ 5., 12.],\n",
      "        [21., 32.]], dtype=torch.float64)\n",
      "[[0.2        0.33333333]\n",
      " [0.42857143 0.5       ]] \n",
      "\n",
      "tensor([[0.2000, 0.3333],\n",
      "        [0.4286, 0.5000]], dtype=torch.float64)\n",
      "[[ 6.  8.]\n",
      " [10. 12.]] \n",
      "\n",
      "tensor([[ 6.,  8.],\n",
      "        [10., 12.]], dtype=torch.float64)\n",
      "[[-4. -4.]\n",
      " [-4. -4.]] \n",
      "\n",
      "tensor([[-4., -4.],\n",
      "        [-4., -4.]], dtype=torch.float64)\n",
      "[[19. 22.]\n",
      " [43. 50.]] \n",
      "\n",
      "tensor([[19., 22.],\n",
      "        [43., 50.]], dtype=torch.float64)\n",
      "[[0.2        0.33333333]\n",
      " [0.42857143 0.5       ]] \n",
      "\n",
      "tensor([[0.2000, 0.3333],\n",
      "        [0.4286, 0.5000]], dtype=torch.float64)\n",
      "[[1. 2.]\n",
      " [3. 4.]] \n",
      "\n",
      "[[1. 3.]\n",
      " [2. 4.]] \n",
      "\n",
      "tensor([[1., 3.],\n",
      "        [2., 4.]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "a = np.array([[1., 2.], [3., 4.]])\n",
    "b = np.array([[5., 6.], [7., 8.]])\n",
    "\n",
    "V = torch.from_numpy(a)\n",
    "M = torch.from_numpy(b)\n",
    "\n",
    "# addition\n",
    "print(a+b, '\\n')\n",
    "print(V+M)\n",
    "\n",
    "# subtraction\n",
    "print(b-a, '\\n')\n",
    "print(M-V)\n",
    "\n",
    "# multiplication\n",
    "print(a*b, '\\n')\n",
    "print(V*M)\n",
    "\n",
    "# division\n",
    "print(a/b, '\\n')\n",
    "print(V/M)\n",
    "\n",
    "# matrix addition\n",
    "print(np.add(a,b), '\\n')\n",
    "print(torch.add(V,M))\n",
    "\n",
    "# matrix subtraction\n",
    "print(np.subtract(a,b), '\\n')\n",
    "print(torch.sub(V,M))\n",
    "\n",
    "# matrix multiplication\n",
    "print(np.dot(a,b), '\\n')\n",
    "print(torch.mm(V,M))\n",
    "\n",
    "# matrix division\n",
    "print(np.divide(a,b), '\\n')\n",
    "print(torch.div(V,M))\n",
    "\n",
    "# matrix transpose\n",
    "print(a, '\\n')\n",
    "print(np.transpose(a), '\\n')\n",
    "print(torch.t(V))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a comprehensive mapping between Numpy and PyTorch matrix operations, refer to [this tutorial](https://github.com/wkentaro/pytorch-for-numpy-users)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Machine learning workflow in PyTorch\n",
    "Just like sklearn's flow of (1) constructor, (2) `.fit`, and (3) `.transform` or `.predict`, PyTorch has its own workflow for a machine learning task:\n",
    "\n",
    "1. Define the model. The module [torch.nn](https://pytorch.org/docs/stable/nn.html) provides many classes for the different types of layer in a neural network; however, each layer can also act as an independent model (e.g., a `Linear` layer can replicate a linear regression model).\n",
    "\n",
    "1. Define the loss function and optimizer. The available loss functions, such as `MSELoss` and `CrossEntropyLoss`, are listed in the `torch.nn` modules. For the optimizer, while we have only seen gradient descent so far, there are many other strategies supported by the [torch.optim](https://pytorch.org/docs/stable/optim.html) module. A more recent improvement to stochastic gradient descent is the [Adam (Adaptive Moment Optimization)](https://blog.paperspace.com/intro-to-optimization-momentum-rmsprop-adam/) algorithm, which we will use in Project 5.\n",
    "\n",
    "1. Train the model for `n_epoch` epochs. In each iteration, the training code would look roughly as follows:\n",
    "\n",
    "```python\n",
    "def train(model, X, Y):\n",
    "    # forward pass, compute loss value\n",
    "    Y_hat = model(X)\n",
    "    loss = criterion(Y_hat, Y)\n",
    "\n",
    "    # reset gradient to prepare for backward pass\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # backward pass\n",
    "    loss.backward()\n",
    "    optimzier.step()\n",
    "```\n",
    "\n",
    "We should also note the difference between an epoch and an iteration. Because CNN typically uses stochastic gradient descent (or its variations), you will frequently see the following code structure:\n",
    "\n",
    "```python\n",
    "for epoch in range(n_epochs):\n",
    "    for X, Y in minibatches:\n",
    "        train(model, X, Y)\n",
    "```\n",
    "\n",
    "In this case, each call to `train(model, X, Y)` is one iteration, as it goes through one minibatch, and an epoch is counted as one pass through all the minibatches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's go through some examples of the above process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Linear regression example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Loss: 4.828\n",
      "Epoch [20/100], Loss: 1.3768\n",
      "Epoch [30/100], Loss: 0.5044\n",
      "Epoch [40/100], Loss: 0.2775\n",
      "Epoch [50/100], Loss: 0.2126\n",
      "Epoch [60/100], Loss: 0.1889\n",
      "Epoch [70/100], Loss: 0.176\n",
      "Epoch [80/100], Loss: 0.1662\n",
      "Epoch [90/100], Loss: 0.1578\n",
      "Epoch [100/100], Loss: 0.1501\n",
      "\n",
      "weight Parameter containing:\n",
      "tensor([[ 2.7708, -6.3034]], requires_grad=True)\n",
      "bias Parameter containing:\n",
      "tensor([-0.1549], requires_grad=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-9.6376],\n",
       "        [-6.0979],\n",
       "        [ 2.1346],\n",
       "        [-6.3231],\n",
       "        [-2.7696]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim\n",
    "\n",
    "# fix random seed for consistent results\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# input data\n",
    "X = torch.tensor([[0.9, 1.9], [1.95, 1.8], [1.85, 0.45], [1.3, 1.55], [1.9, 1.25]])\n",
    "Y = torch.tensor([-9.5, -6.8,  2.3, -5.9, -2.6]).reshape(-1, 1)\n",
    "\n",
    "# model specification\n",
    "alpha, n_epochs = 1e-1, 100\n",
    "model = nn.Linear(X.shape[1], 1)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = alpha)\n",
    "\n",
    "# training epochs\n",
    "for epoch in range(n_epochs):\n",
    "    Y_hat = model(X)\n",
    "    loss = criterion(Y_hat, Y)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{n_epochs}], Loss: {round(loss.item(), 4)}')\n",
    "\n",
    "print()\n",
    "# print model parameters after training\n",
    "for name, param in model.named_parameters():\n",
    "    print(name, param)\n",
    "    \n",
    "# print predictions after training\n",
    "model(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that for `MSELoss`, even though each output is only a scalar value, Pytorch still expects the output to be a 2D matrix, hence the `.reshape` call we did for `Y`, which converts it to shape `(n,1)`. This may not be the case for other loss functions, e.g., `CrossEntropyLoss` expects a 1D output vector, so make sure to check the documentation carefully."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Convolutional neural network\n",
    "\n",
    "We first define a convolutional network model with the following structure:\n",
    "\n",
    "1. Input layer\n",
    "1. Convolutional layer with $K = 5, S = 1, P = 2$\n",
    "1. ReLU layer\n",
    "1. Maxpool layer with $F = 2, S = 2$\n",
    "1. Convolutional layer with $K = 5, S = 1, P = 2$\n",
    "1. ReLU layer\n",
    "1. Maxpool layer with $F = 2, S = 2$.\n",
    "1. Fully connected layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyCNN, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        # the output of self.layers is a matrix of shape (7, 7, 32)\n",
    "        # so when flattened, it becomes a vector of shape 7 * 7 * 32\n",
    "        self.fc = nn.Linear(7*7*32, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layers(x)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        return self.fc(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, to create a CNN model, we create a class `MyCNN` that inherits from `nn.Module`, where we only need to implement two functions:\n",
    "\n",
    "1. Constructor `__init__`. This calls the parent's constructor and defines instance variables that represent the network layers. \n",
    "\n",
    "1. Feedforward procedure `forward`. This defines how an input tensor should be processed through each layer in the network. One trick to make this function concise is to put the layers in `__init__` into an `nn.Sequential` object, as we showed above, which allows us to get the output from all of the member layers with just one line of code in `forward`, namely `out = self.layers(x)`.\n",
    "\n",
    "You may notice that we did not put the final `nn.Linear` layer into `self.layers`. The reason is that the output from the second `nn.MaxPool2d` needs to be flattened to a vector, before it is input to `nn.Linear`. We perform this flattening step inside `forward`, in the line `out = out.reshape(out.size(0), -1)`.\n",
    "\n",
    "Alternatively, with a recent update, PyTorch now supports an `nn.Flatten` layer as well, so we could move the flattening step to `__init__`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCNN2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyCNN2, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(7*7*32, n_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that all of the data processing steps can now be included in `self.layers`, so the `forward` function only needs to return the output of `self.layers`. In general, the takeaway message is: if an operation is supported by `torch.nn`, put it in an `nn.Sequential` object in `__init__`; otherwise, perform it in `forward`. This setting allows for great flexibility in how we want to define our network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's run our network. For this example we will use the MNIST (Modified National Institute of Standards and Technology) dataset. Here each data point is a $28 \\times 28$ integer matrix that represents a black-and-white image of a handwritten digit.\n",
    "\n",
    "![mnist](https://www.researchgate.net/profile/Steven_Young11/publication/306056875/figure/fig1/AS:393921575309346@1470929630835/Example-images-from-the-MNIST-dataset.png)\n",
    "\n",
    "Our task is to predict a digit based on its image; in other words, this is a 10-class classification problem. MNIST is one of the standard datasets included in the `torchvision` package, so we can load it directly. We also use the `DataLoader` utility from PyTorch to get the minibatches used for training and testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "mnist_trainset = datasets.MNIST(root=\"./\", train=True, download=True, transform=transforms.ToTensor())\n",
    "mnist_testset = datasets.MNIST(root=\"./\", train=False, download=True, transform=transforms.ToTensor())\n",
    "trainloader = torch.utils.data.DataLoader(mnist_trainset, batch_size=64, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(mnist_testset, batch_size=1000,shuffle=False)\n",
    "n_classes = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create an instance of `MyCNN` and train the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Loss: 0.0192\n",
      "Epoch [2/3], Loss: 0.027\n",
      "Epoch [3/3], Loss: 0.0096\n"
     ]
    }
   ],
   "source": [
    "model = MyCNN()\n",
    "alpha, n_epochs = 1e-2, 3\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = alpha)\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(n_epochs):\n",
    "    for images, labels in trainloader:\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'Epoch [{epoch+1}/{n_epochs}], Loss: {round(loss.item(), 4)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now evaluate our trained model on the test data. We first call `torch.no_grad()` to disable gradient computation. This is useful when we are only doing inference and do not update the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on the 10000 test images: 97.41\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in testloader:\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    print(f'Test Accuracy of the model on the 10000 test images: {100 * correct / total}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see an accuracy of around 97% on the test data even after only 3 training epochs!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. Saving and loading a model\n",
    "To save a model, we first retrieve its state and parameter values by `model.state_dict()`, then call `torch.save` and specify the file to save to. To load a saved model, we first create an instance of the same model class and \"fill in\" the parameter values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.save(model.state_dict(), \"saved_model_params.pth\")\n",
    "loaded_model = MyCNN()\n",
    "loaded_model.load_state_dict(torch.load(\"saved_model_params.pth\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch also allows for model saving *during* the training phase, so that if any interruption happens while the model is being trained, we can load the latest checkpoint instead of having to re-train from the beginning. See the [official documentation](https://pytorch.org/tutorials/beginner/saving_loading_models.html) for more details."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
