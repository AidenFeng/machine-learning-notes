{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Machine Learning\n",
    "This primer provides a brief introduction to the field of machine learning, which can be roughly described as the study of pattern recognition and prediction from the data. The theories behind machine learning have been around for a while (for example, least square regression is typically [credited to Gauss](https://en.wikipedia.org/wiki/Least_squares) in the 1800s), primarily taking inspirations from statistics, but machine learning only gained popularity recently thanks to the availability of large dataset and powerful computers.\n",
    "\n",
    "In the scope of this primer, we will only cover the common machine learning notations and procedures to give you a sense of the field. You will learn more about when to use which model and under which configuration in a follow-up machine learning course (e.g., 10601, 10701)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Machine learning notations\n",
    "A machine learning problem can typically be defined in terms of the following notations:\n",
    "1. **Input data $X \\in \\mathbb{R}^{n \\times d}$**. If we have $n$ input data points, each of which is a $d$-dimensional vector, we can stack them together into a matrix $X$ of size $n \\times d$. The $i$-th data point, or the $i$-th row of $X$, is denoted as $x^{(i)}$.\n",
    "\n",
    "\n",
    "2. **Output $Y \\in \\mathcal Y^n$**. Each output is a quantity in some set $\\mathcal Y$, which is the output space. In regression, most output spaces will be real-valued scalars, while in classification, most of them will be binary or multivariate discrete quantities. The output of the $i$-th data point $x^{(i)}$ is denoted as $y^{(i)}$.\n",
    "\n",
    "\n",
    "3. **Parameters $\\theta \\in \\mathbb{R}^d$**. Together with the hypothesis function, the parameters define our hypothesized relationship between $X$ and $Y$. We try to optimize these numbers in order to make the best prediction. Note that there are also machine learning models without parameters; these are called non-parametric models.\n",
    "\n",
    "\n",
    "4. **Hypothesis function $h_\\theta: \\mathbb{R}^n \\to \\hat{\\mathcal Y}$**. A hypothesis funtion is a mapping from the input space $\\mathbb{R}^n$ to the prediction space $\\hat{\\mathcal Y}$. In regression, $\\hat{\\mathcal Y} = \\mathcal Y$, but in classification this may not always be the case, although there is often a straightforward mapping between the two, as we will see.\n",
    "\n",
    "\n",
    "5. **Loss function $l: \\hat{\\mathcal Y} \\times \\mathcal Y \\to \\mathbb R$**. A loss function is a mapping from predictions and true outputs to positive real numbers. It serves as a measurement for the prediction. The quantity is small when we make a good prediction and vise versa.\n",
    "\n",
    "Another commonly encountered term is **hyperparameter**, which denotes the model configurations that come from human inputs rather than being computationally derived from the data. Examples of hyperparameters include the number of training iterations, the learning rate, and the regularizer value.\n",
    "\n",
    "To see how the above concepts look like in practice, let's take a look at three common supervised machine learning models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Machine learning model examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Linear Regression\n",
    "#### 2.1.1. Definition\n",
    "Linear Regression attempts to model the relationship between the input $X$ and output $Y$ by a line, or more generally, a hyperplane $y = b + \\theta_1 x_1 + \\theta_2 x_2 + \\ldots + \\theta_d x_d$. A linear regression model can be formally described as follows:\n",
    "\n",
    "1. **Input data** $X \\in \\mathbb{R}^{n \\times d}$.\n",
    "1. **Output** $Y \\in \\mathcal{Y}^n$, where typically $\\mathcal Y = \\mathbb R$.\n",
    "1. **Parameters** weight vector $\\theta \\in \\mathbb{R}^{d}$ and intercept term $b \\in \\mathbb R$.\n",
    "1. **Hypothesis function** $h_\\theta(x) = b + \\sum_{j=1}^d \\theta_j x_j$.\n",
    "1. **Loss function** $l(h_\\theta(x), y) = (h_\\theta(x) - y)^2$.\n",
    "\n",
    "#### 2.1.2. Optimization\n",
    "Linear Regression attempts to find the parameters $\\theta$ that minimize the sum of the loss values at every data point, i.e., the mean squared error\n",
    "$$\\mathcal{L}(\\theta, b) = \\frac{1}{2n} \\sum_{i=1}^n \\left(h_\\theta(x^{(i)}) - y^{(i)} \\right)^2  = \\frac{1}{2n} \\sum_{i=1}^n \\left(b + \\theta^T x^{(i)} - y^{(i)} \\right)^2.$$\n",
    "To reduce the possibility of overfitting, we often want to constrain the magnitude of the weight values. This can be done by adding a regularization term to the loss function:\n",
    "\n",
    "\\begin{equation}\n",
    "\\boxed{\\mathcal{L}(\\theta, b) = \\frac{1}{2n} \\left[\\sum_{i=1}^n \\left(b + \\theta^T x^{(i)} - y^{(i)} \\right)^2 + \\lambda \\sum_{j=1}^d \\theta_j^2 \\right],}\n",
    "\\end{equation}\n",
    "where the hyperparameter $\\lambda$ is called the *regularizer*, in the sense that it determines how much large values of $\\theta$ should be penalized. From the view of bias-variance tradeoff, a higher $\\lambda$ results in higher bias and lower variance, while a lower $\\lambda$ results in lower bias and higher variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A popular method to minimize this loss function is called *gradient descent*, where we iteratively update the weight parameters in the direction of steepest descent as defined by the negative of the gradient, i.e., \n",
    "\n",
    "$$\\begin{aligned}\n",
    "    b & := b - \\alpha \\cdot \\frac{\\partial \\mathcal L(\\theta, b)}{\\partial b}, \\\\\n",
    "    \\theta & := \\theta - \\alpha \\cdot \\frac{\\partial \\mathcal L(\\theta, b)}{\\partial \\theta},\n",
    "\\end{aligned}$$\n",
    "where the hyperparameter $\\alpha$ is called the *learning rate* and determines how large each gradient step is. Let's now try computing the gradients for $b$ and $\\theta$ based on the formulas we have so far.\n",
    "\n",
    "$$\\begin{aligned}\n",
    "    \\frac{\\partial \\mathcal L(\\theta, b)}{\\partial b} \n",
    "    & = \\frac{\\partial}{\\partial b} \\left[\\frac{1}{2n} \\sum_{i=1}^n \\left(b + \\theta^T x^{(i)} - y^{(i)} \\right)^2 + \\frac{\\lambda}{2n} \\sum_{j=1}^d \\theta_j^2 \\right] \\\\\n",
    "    & = \\frac{1}{n} \\sum_{i=1}^n \\left(b + \\theta^T x^{(i)} - y^{(i)} \\right), \\\\\n",
    "    \\frac{\\partial \\mathcal L(\\theta, b)}{\\partial \\theta_k} \n",
    "    & = \\frac{\\partial}{\\partial \\theta_k} \\left[\\frac{1}{2n} \\sum_{i=1}^n \\left(b + \\theta^T x^{(i)} - y^{(i)} \\right)^2 + \\frac{\\lambda}{2n} \\sum_{j=1}^d \\theta_j^2 \\right] \\\\\n",
    "    & = \\frac{1}{n} \\sum_{i=1}^n \\left(b + \\theta^T x^{(i)} - y^{(i)}\\right) \\cdot \\frac{\\partial}{\\partial \\theta_k} \\left(b + \\theta^T x^{(i)} - y^{(i)}\\right) + \\frac{\\lambda \\theta_k}{n} \\\\\n",
    "    & = \\frac{1}{n} \\sum_{i=1}^n \\left(b + \\theta^T x^{(i)} - y^{(i)} \\right) x^{(i)}_k + \\frac{\\lambda \\theta_k}{n}.\n",
    "\\end{aligned}$$\n",
    "We also note that the expression for $\\frac{\\partial \\mathcal L(\\theta, b)}{\\partial \\theta_k}$ can also be expressed more compactly in vector notation:\n",
    "\n",
    "\\begin{equation}\n",
    "    \\frac{\\partial \\mathcal L(\\theta, b)}{\\partial \\theta} = \\frac{1}{n} \\sum_{i=1}^n \\left(b + \\theta^T x^{(i)} - y^{(i)} \\right) x^{(i)} + \\frac{\\lambda \\theta}{n}.\n",
    "\\end{equation}\n",
    "\n",
    "This leads us to the gradient descent algorithm for linear regression as follows:\n",
    "\n",
    "1. Initialize $b = 0$ and $\\theta$ as a vector of 0s.\n",
    "1. Repeat `n_iters` times:\n",
    "\n",
    "\\begin{align}\n",
    "    b & := b - \\alpha \\cdot \\frac{1}{n} \\sum_{i=1}^n \\left(b + \\theta^T x^{(i)} - y^{(i)} \\right), \\\\\n",
    "    \\theta & := \\theta - \\alpha \\cdot \\left[\\frac{1}{n} \\sum_{i=1}^n \\left(b + \\theta^T x^{(i)} - y^{(i)} \\right) x^{(i)} + \\frac{\\lambda \\theta}{n} \\right].\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.3. Worked example\n",
    "Let's apply linear regression to the following input $X$ and output $Y$:\n",
    "$$X = \\begin{pmatrix} \n",
    "    0.9 & 1.9 \\\\\n",
    "    1.95 & 1.8 \\\\\n",
    "    1.85 & 0.45 \\\\\n",
    "    1.3 & 1.55 \\\\\n",
    "    1.9 & 1.25\n",
    "\\end{pmatrix}, \\quad Y = \\begin{pmatrix} -9.5 \\\\ -6.8 \\\\ 2.3 \\\\ -5.9 \\\\ -2.6 \\end{pmatrix}.$$\n",
    "We will also pick the hyperparameters $\\alpha = 10^{-2}$ and $\\lambda = 10^{-4}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Before gradient descent**:\n",
    "\n",
    "We initialize $b = 0$ and $\\theta = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}$.\n",
    "The loss function value is then\n",
    "\\begin{align*}\n",
    "\\mathcal{L}(\\theta, b) & = \\frac{1}{2n} \\left[\\sum_{i=1}^n \\left(b + \\theta^T x^{(i)} - y^{(i)} \\right)^2 + \\lambda \\sum_{j=1}^d \\theta_j^2 \\right] \\\\\n",
    "& = \\frac{1}{10} \\sum_{i=1}^5 (-y^{(i)})^2 = 18.335.\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1st iteration**:\n",
    "\n",
    "We update $b$ and $\\theta$ based on the gradient:\n",
    "\\begin{align*}\n",
    "    b & := b - \\alpha \\cdot \\frac{1}{n} \\sum_{i=1}^n \\left(b + \\theta^T x^{(i)} - y^{(i)} \\right) \\\\\n",
    "    & = 0 - 10^{-2} \\cdot \\frac{1}{5} \\sum_{i=1}^5 (-y^{(i)}) = -0.045. \\\\\n",
    "    \\theta & := \\theta - \\alpha \\cdot \\left[\\frac{1}{n} \\sum_{i=1}^n \\left(b + \\theta^T x^{(i)} - y^{(i)} \\right) x^{(i)} + \\frac{\\lambda \\theta}{n} \\right] \\\\\n",
    "    & = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix} - 10^{-2} \\left[ \\frac{1}{5} \\sum_{i=1}^5 -y^{(i)}x^{(i)} \\right] = \\begin{pmatrix} -0.06033 \\\\ -0.0833 \\end{pmatrix}.\n",
    "\\end{align*}\n",
    "\n",
    "Note that the gradient of $\\theta$ is computed using the old value of $b$, i.e., $b = 0$, not the new value $b = -0.045$. In other words, the updates of $b$ and $\\theta$ can be considered to take place in parallel.\n",
    "\n",
    "With these new parameter values, we can compute the loss function value again:\n",
    "\\begin{align*}\n",
    "\\mathcal{L}(\\theta, b) & = \\frac{1}{2n} \\left[\\sum_{i=1}^n \\left(b + \\theta^T x^{(i)} - y^{(i)} \\right)^2 + \\lambda \\sum_{j=1}^d \\theta_j^2 \\right] \\\\\n",
    "& = 17.10814680143814.\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2nd iteration**:\n",
    "\n",
    "We update $b$ and $\\theta$ based on the gradient:\n",
    "\\begin{align*}\n",
    "    b & := b - \\alpha \\cdot \\frac{1}{n} \\sum_{i=1}^n \\left(b + \\theta^T x^{(i)} - y^{(i)} \\right) \\\\\n",
    "    & =-0.087438916. \\\\\n",
    "    \\theta & := \\theta - \\alpha \\cdot \\left[\\frac{1}{n} \\sum_{i=1}^n \\left(b + \\theta^T x^{(i)} - y^{(i)} \\right) x^{(i)} + \\frac{\\lambda \\theta}{n} \\right] \\\\\n",
    "    & = \\begin{pmatrix} -0.11660027 \\\\ -0.16287898 \\end{pmatrix}.\n",
    "\\end{align*}\n",
    "\n",
    "With these new parameter values, we can compute the loss function value again:\n",
    "\\begin{align*}\n",
    "\\mathcal{L}(\\theta, b) & = \\frac{1}{2n} \\left[\\sum_{i=1}^n \\left(b + \\theta^T x^{(i)} - y^{(i)} \\right)^2 + \\lambda \\sum_{j=1}^d \\theta_j^2 \\right] \\\\\n",
    "& = 16.0080447832965.\n",
    "\\end{align*}\n",
    "\n",
    "We see that the loss values steadily decrease from 18 to 17 to 16 after 2 iterations, so our gradient descent is indeed working. After 1000 iterations, we can achieve a loss of only 0.08."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.4. Data Normalization\n",
    "Note that in the gradient descent algorithm above, we are using the same learning rate $\\alpha$ to update the intercept $b$ and every dimension $\\theta_j$. This will cause issues if the input dimensions have different scales (e.g., $x_1$ ranges from 0-1 while $x_2$ ranges from 10-100). While it is possible to have a separate learning rate $\\alpha_j$ for every dimension $j$ (and an $\\alpha_0$ for the intercept), it can get cumbersome when the input data is high dimensional. Instead, we can make our lives much easier by transforming every dimension to the same scale, so that we only need one learning rate $\\alpha$. This task can be done in a number of different ways:\n",
    "\n",
    "1. Normalize data to between 0 and 1:\n",
    "$$\\tilde{x}^{(i)}_j = \\frac{x_j^{(i)} - \\min_i x_j^{(i)}}{\\max_i x_j^{(i)} - \\min_i x_j^{(i)}}.$$\n",
    "\n",
    "1. Normalize data to between -1 and 1:\n",
    "$$\\tilde{x}^{(i)}_j = \\frac{2(x_j^{(i)} - \\min_i x_j^{(i)})}{\\max_i x_j^{(i)} - \\min_i x_j^{(i)}} - 1.$$\n",
    "\n",
    "1. Normalize data to have zero mean and unit variance:\n",
    "$$\\tilde{x}_j^{(i)} = \\frac{{x}_j^{(i)} - \\mu_j}{\\sigma_j},$$\n",
    "where $\\mu_j$ and $\\sigma_j$ are the mean and standard deviation of $\\{x_j^{(i)}\\}_{i=1}^n$.\n",
    "\n",
    "While the best normalization method is data-dependent, the third strategy (zero mean and unit variance) is most commonly used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Logistic Regression\n",
    "#### 2.2.1. Definition\n",
    "Despite having \"regression\" in its name, logistic regression is actually a classification method that attempts to model the probability that a data point is in the positive or negative class. A logistic regression model can be formally described as follows:\n",
    "\n",
    "1. **Input data** $X \\in \\mathbb{R}^{n \\times d}$.\n",
    "1. **Output** $Y \\in \\{-1, 1\\}^n$.\n",
    "1. **Parameters** weight vector $\\theta \\in \\mathbb{R}^{d}$ and intercept term $b \\in \\mathbb R$.\n",
    "1. **Hypothesis function** $h_\\theta(x) = b + \\sum_{j=1}^d \\theta_j x_j$. We predict $y = 1$ if $h_\\theta(x) \\ge 0$ and $y = -1$ otherwise.\n",
    "1. **Loss function** $l(h_\\theta(x), y) = \\log(1 + \\exp(-h_\\theta(x) \\cdot y))$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.2. Optimization\n",
    "Logistic Regression attempts to find the parameters $\\theta$ that minimize the sum of the loss values at every data point, i.e., the mean logistic loss\n",
    "$$\\mathcal L(\\theta, b) = \\frac{1}{2n}{\\sum_{i=1}^{n}} \\log\\left(1 + \\exp(-h_\\theta(x^{(i)}) \\cdot y^{(i)}) \\right).$$\n",
    "To reduce the possibility of overfitting, we often want to constrain the magnitude of the weight values. This can be done by adding a regularization term to the loss function:\n",
    "\n",
    "\\begin{equation}\n",
    "\\boxed{\\mathcal{L}(\\theta, b) = \\frac{1}{2n} \\left[\\sum_{i=1}^n \\log\\left(1 + \\exp \\left(-h_\\theta(x^{(i)}) \\cdot y^{(i)} \\right) \\right) + \\lambda \\sum_{j=1}^d \\theta_j^2 \\right],}\n",
    "\\end{equation}\n",
    "\n",
    "where the hyperparameter $\\lambda$ is the *regularizer*.\n",
    "\n",
    "We can derive the gradient in the same manner as linear regression earlier, by computing $\\frac{\\partial \\mathcal L(\\theta, b)}{\\partial b}$ and $\\frac{\\partial \\mathcal L(\\theta, b)}{\\partial \\theta}$. This gives us the following gradient descent algorithm for logistic regression:\n",
    "\n",
    "1. Initialize $b = 0$ and $\\theta$ as a vector of 0s.\n",
    "1. Repeat `n_iters` times:\n",
    "\n",
    "\\begin{align}\n",
    "    b & := b - \\alpha \\cdot  \\frac{1}{2n} \\sum_{i=1}^n \\frac{-y^{(i)}}{1 + \\exp(h_\\theta(x^{(i)}) \\cdot y^{(i)})}, \\\\\n",
    "    \\theta & := \\theta - \\alpha \\cdot \\frac{1}{2n} \\cdot \\left[\\sum_{i=1}^n \\frac{-x^{(i)} y^{(i)}}{1 + \\exp(h_\\theta(x^{(i)}) \\cdot y^{(i)})} + 2\\lambda \\theta \\right]\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.3. Worked example\n",
    "Let's apply logistic regression to the following input $X$ and label $Y$:\n",
    "$$X = \\begin{pmatrix}\n",
    "    -2 & 4 \\\\\n",
    "    4 & 1 \\\\\n",
    "    1 & 6 \\\\\n",
    "    2 & 4 \\\\\n",
    "    6 & 2\n",
    "\\end{pmatrix}, \\quad Y = \\begin{pmatrix} -1 \\\\ -1 \\\\ 1 \\\\ 1 \\\\ 1 \\end{pmatrix}.$$\n",
    "We will also pick the hyperparameters $\\alpha = 10^{-2}$ and $\\lambda = 10^{-4}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Before gradient descent**:\n",
    "\n",
    "We initialize $b = 0$ and $\\theta = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}$. The loss function value is then\n",
    "$$\\begin{aligned}\n",
    "\\mathcal{L}(\\theta, b) & = \\frac{1}{2n} \\left[\\sum_{i=1}^n \\log\\left(1 + \\exp \\left(-h_\\theta(x^{(i)}) \\cdot y^{(i)} \\right) \\right) + \\lambda \\sum_{j=1}^d \\theta_j^2 \\right] \\\\\n",
    "& = \\frac{1}{10} \\sum_{i=1}^5 \\log(1 + \\exp(0)) = 0.3465735902799727.\n",
    "\\end{aligned}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1st iteration**:\n",
    "\n",
    "We update $b$ and $\\theta$ based on the gradient:\n",
    "\\begin{align*}\n",
    "    b & := b - \\alpha \\cdot  \\frac{1}{2n} \\sum_{i=1}^n \\frac{y^{(i)}}{1 + \\exp(h_\\theta(x^{(i)}) \\cdot y^{(i)})} \\\\\n",
    "    & = 0.0005. \\\\\n",
    "    \\theta & := \\theta - \\alpha \\cdot \\left[\\frac{1}{2n} \\sum_{i=1}^n \\frac{-x^{(i)} y^{(i)}}{1 + \\exp(h_\\theta(x^{(i)}) \\cdot y^{(i)})} + \\frac{\\lambda \\theta}{n} \\right] \\\\\n",
    "    & = \\begin{pmatrix} 0.0035 \\\\ 0.0035 \\end{pmatrix}.\n",
    "\\end{align*}\n",
    "\n",
    "With these new parameter values, we can compute the loss function value again:\n",
    "\\begin{align*}\n",
    "\\mathcal{L}(\\theta, b) & = \\frac{1}{2n} \\left[\\sum_{i=1}^n \\left(b + \\theta^T x^{(i)} - y^{(i)} \\right)^2 + \\lambda \\sum_{j=1}^d \\theta_j^2 \\right] \\\\\n",
    "& = 0.34657359052497266.\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2nd iteration**:\n",
    "\n",
    "We update $b$ and $\\theta$ based on the gradient:\n",
    "\\begin{align*}\n",
    "    b & := b - \\alpha \\cdot  \\frac{1}{2n} \\sum_{i=1}^n \\frac{y^{(i)}}{1 + \\exp(h_\\theta(x^{(i)}) \\cdot y^{(i)})} \\\\\n",
    "    & = 0.000974876145059743. \\\\\n",
    "    \\theta & := \\theta - \\alpha \\cdot \\left[\\frac{1}{2n} \\sum_{i=1}^n \\frac{-x^{(i)} y^{(i)}}{1 + \\exp(h_\\theta(x^{(i)}) \\cdot y^{(i)})} + \\frac{\\lambda \\theta}{n} \\right] \\\\\n",
    "    & = \\begin{pmatrix} 0.006926 \\\\ 0.00691475 \\end{pmatrix}.\n",
    "\\end{align*}\n",
    "\n",
    "With these new parameter values, we can compute the loss function value again:\n",
    "\\begin{align*}\n",
    "\\mathcal{L}(\\theta, b) & = \\frac{1}{2n} \\left[\\sum_{i=1}^n \\left(b + \\theta^T x^{(i)} - y^{(i)} \\right)^2 + \\lambda \\sum_{j=1}^d \\theta_j^2 \\right] \\\\\n",
    "& = 0.34412708739815534.\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Support Vector Machine\n",
    "#### 2.3.1. Definition\n",
    "In its base form, support vector machine aims to identify a linear decision boundary that maximizes the margin of separation between examples of different classes. A support vector machine model can be formally described as follows:\n",
    "\n",
    "1. **Input data** $X \\in \\mathbb{R}^{n \\times d}$.\n",
    "1. **Output** $Y \\in \\{-1, 1\\}^n$.\n",
    "1. **Parameters** weight vector $\\theta \\in \\mathbb{R}^{d}$ and intercept term $b \\in \\mathbb R$.\n",
    "1. **Hypothesis function** $h_\\theta(x) = b + \\sum_{j=1}^d \\theta_j x_j$. We predict $y = 1$ if $h_\\theta(x) \\ge 0$ and $y = -1$ otherwise.\n",
    "1. **Loss function** $l(h_\\theta(x), y) = \\max\\{1 - h_\\theta(x) \\cdot y, 0\\}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.2. Optimization\n",
    "Support vector machine attempts to find the parameters $\\theta$ and $b$ that minimize the sum of the loss values at every data point, i.e., the mean hinge loss\n",
    "$$\\mathcal L(\\theta, b) = \\frac{1}{2n} \\sum_{i=1}^n \\max\\{1 - h_\\theta(x^{(i)}) \\cdot y^{(i)}\\}.$$\n",
    "To reduce the possibility of overfitting, we often want to constrain the magnitude of the weight values. This can be done by adding a regularization term to the loss function:\n",
    "\n",
    "\\begin{equation}\n",
    "\\boxed{\\mathcal{L}(\\theta, b) = \\frac{1}{2n} \\left[\\sum_{i=1}^n \\max\\{1 - h_\\theta(x^{(i)}) \\cdot y^{(i)}\\} + \\lambda \\sum_{j=1}^d \\theta_j^2 \\right],}\n",
    "\\end{equation}\n",
    "\n",
    "where the hyperparameter $\\lambda$ is the *regularizer*.\n",
    "\n",
    "We can derive the gradient in the same manner as linear regression earlier, by computing $\\frac{\\partial \\mathcal L(\\theta, b)}{\\partial b}$ and $\\frac{\\partial \\mathcal L(\\theta, b)}{\\partial \\theta}$. This gives us the following gradient descent algorithm for logistic regression:\n",
    "\n",
    "1. Initialize $b = 0$ and $\\theta$ as a vector of 0s.\n",
    "1. Repeat `n_iters` times:\n",
    "\n",
    "\\begin{align}\n",
    "    b & := b - \\alpha \\cdot  \\frac{1}{2n} \\sum_{i=1}^n -y^{(i)} \\mathbb{1}\\left(h(x^{(i)}) \\cdot y^{(i)} \\le 1 \\right), \\\\\n",
    "    \\theta & := \\theta - \\alpha \\cdot \\frac{1}{2n} \\cdot \\left[\\sum_{i=1}^n -x^{(i)} y^{(i)} \\mathbb{1}\\left(h(x^{(i)}) \\cdot y^{(i)} \\le 1 \\right) + 2\\lambda \\theta \\right]\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. A note about multi-class classification\n",
    "We have seen two examples of binary classfication models: linear regression and support vector machine. In essence, they both perform classification by dividing the input space into the positive and negative region based on the hyperplane $b + \\theta^Tx = 0$. The follow-up question, then, is what to in case there are more than two classes. There are two ways to deal with this scenario.\n",
    "\n",
    "### 3.1. One-versus-rest approach\n",
    "Assume there are $k$ classes $\\{1, 2, \\ldots, k\\}$. In the one-versus-rest approach, we would train $k$ binary classifiers where classifier $c$ (with weight $\\theta_c$ and intercept $b_c$) predicts whether a data point belongs to class $c$ or not. Then, when given a new data point $x$, we follow the classifier that yields the maximum hypothesis function value. In other words, the predicted label for $x$ would be\n",
    "$$\\hat y = \\underset{c \\in C}{\\operatorname{argmax}} h_{\\theta_c}(x).$$\n",
    "\n",
    "This is more of a heuristic-oriented approach, but it often works well in practice.\n",
    "\n",
    "### 3.2. Using native loss function\n",
    "We can also define a new loss function for the multi-class case and minimize it using gradient descent. With logistic regression, a natural extension to the logistic loss is the cross-entropy loss\n",
    "\n",
    "$$\\boxed{\\mathcal L(\\Theta) = - \\frac{1}{n} \\left[ \\sum_{i=1}^{n}\\sum_{j \\in C} \\mathbb{1}(j = y^{(i)}) \\log \\frac{\\exp(h_{\\theta_c}(x^{(i)}) - m_i)}{\\sum_{c \\in C} \\exp(h_{\\theta_c}(x^{(i)}) - m_i)}\\right] + \\lambda \\sum_{c \\in C}\\|\\theta_c\\|_2^2},$$\n",
    "where $\\Theta$ is the matrix of all the weight vectors\n",
    "$$\\Theta =\\left[\\begin{array}{cccc}| & | & | & | \\\\\n",
    "\\theta_1 & \\theta_2 & \\cdots & \\theta_k \\\\\n",
    "| & | & | & |\n",
    "\\end{array}\\right] \\in \\mathbb{R}^{d \\times k}.$$\n",
    "\n",
    "Similarly, with support vector machine, we use the following loss function\n",
    "\n",
    "$$\\boxed{\\mathcal L(\\Theta) = \\frac{1}{n} \\sum_{i=1}^n \\sum_{c \\in C,\\ c \\ne y^{(i)}} \\max\\{0, h_c(x^{(i)}) - h_{y^{(i)}}(x^{(i)}) + 1 \\} + \\lambda \\sum_{c \\in C} \\|\\theta_c\\|_2^2},$$\n",
    "with the same $\\Theta$ notation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Show a worked example of the first 2 iterations of gradient descent, on a small dataset.\n",
    "Use the data from the function test_binary_svm_classifier in the p4 notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Cross validation\n",
    "While we have so far focused on minimizing the loss function on the data used for model training, eventually our goal is to have a *generalizable* model, one that also predicts well on data we have *not seen* (but is assumed to come from the same distribution as the training data).\n",
    "\n",
    "To measure how generalizable a model is, one simple idea is to split our dataset into a training set and a validation set. We then train our model only on the training set, and evaluate its performance on the validation set, which can be considered an approximation of the generalization error. While there is no fixed rule on the size of the training set and validation set, we typically use a 70%/30%, 80%/20% or 90%/10% ratio.\n",
    "\n",
    "A potential issue with this approach is that our model performance may be heavily influenced by the random split; for example, if all the data outliers are included in the validation set and not the training set, our model will perform poorly on them. To address this problem, we can perform multiple splits and compute the average model performance across all the splits instead. This routine is called *k-fold cross validation*, and can be outlined as follows:\n",
    "\n",
    "1. Split the dataset into $k$ folds of roughly equal sizes $X_1, X_2, \\ldots, X_k$.\n",
    "1. Repeat $i$ from $1 \\to k$:\n",
    "    * Train the model on $\\bigcup_{j \\ne i} X_j$ (training set)\n",
    "    * Evaluate its performance $p_i$ on $X_i$ (validation set).\n",
    "1. Return the average of $p_1, p_2, \\ldots, p_k$ as a measure of the model's performance.\n",
    "\n",
    "This procedure is computationally more expensive than using a single hold-out validation set, since we now need to train each model k times. However, the error estimate for each model, now averaged across multiple folds, is likely to be more stable and accurate estimate of its generalization ability.\n",
    "\n",
    "Cross validation is commonly used for model selection, i.e., selecting the best model to go with a given dataset as the one with the highest cross-validated performance. To clarify, the \"model\" terms we use in this section do not refer only to the name of the learning technique; it does not make sense to simply say \"logistic regression works better than support vector machine on this dataset.\" Instead, the term \"model\" represents the complete machine learning procedure, which includes both the learning technique and all of the associated hyperparameters (e.g., logistic regression with L2 norm, 1000 training iterations, learning rate $\\alpha = 10^{-2}$ and regularizer $\\lambda= 10^{-4}$). In Project 4, you will apply cross validation to select $\\alpha$ and $\\lambda$."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
