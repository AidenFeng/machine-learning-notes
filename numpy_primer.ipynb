{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numpy is the core library for scientific computing in Python and especially useful for high-dimensional array operations. You will use this library a lot in your data science work, so let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Numpy basics\n",
    "To use Numpy, we first need to import the numpy package:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arrays\n",
    "Numpy arrays are similar to the array data structures in Java and C: they are fixed-size grids that store homogeneous data, i.e., elements of the same data type. An array of rank $n$ has $n$ dimensions, and its shape is an $n$-element tuple where each element denotes the size of an array along a particular dimension.\n",
    "\n",
    "A simple way to create Numpy arrays is by calling the `np.array` function on an array-like object, for example a Python list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 2)\n",
      "float64\n",
      "2.0\n"
     ]
    }
   ],
   "source": [
    "a = np.array([[1., 2.], [3., 4.]])\n",
    "# a is 2x2 matrix\n",
    "print(a.shape)\n",
    "\n",
    "# type float is inferred\n",
    "print(a.dtype)\n",
    "\n",
    "# element access by a[row_index, col_index]\n",
    "print(a[0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numpy also provides many other functions to create arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.zeros((2,3,4)) # array of zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1.],\n",
       "       [1., 1., 1.],\n",
       "       [1., 1., 1.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.ones((3,3)) # array of ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[100, 100],\n",
       "       [100, 100]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.full((2,2), 100) # constant array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0.],\n",
       "       [0., 1.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.eye(2) # identity matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.5369315 , 2.22893802])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.normal((2, 3)) # random sample from a standard normal distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Caution about array shapes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should emphasize a very common source of confusion: the shape `(2,)` is **different from** the shape `(2,1)` or `(1,2)`; the former is a 1D array while the latters are 2D. As you will see throughout this notebook, the 1D and 2D arrays behave very differently in many matrix operations, so make sure to check your dimensions carefully!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2,)\n",
      "(1, 2)\n",
      "(2, 1)\n"
     ]
    }
   ],
   "source": [
    "a = np.array([1,2])\n",
    "print( a.shape )\n",
    "\n",
    "b = np.array([[1,2]])\n",
    "print( b.shape )\n",
    "\n",
    "c = np.array([[1], [2]])\n",
    "print( c.shape )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note also that the shape `(2,)` for the 1D array from above implies that it has two rows, i.e., it is a **column vector**. Therefore, even when we write `a = np.array([1,2])` in our code, we should always think of it as\n",
    "$$a = \\begin{pmatrix} 1 \\\\ 2 \\end{pmatrix}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a consequence, transposing a 1D array does not change anything -- it will still be a column vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2] (2,)\n",
      "[1 2] (2,)\n"
     ]
    }
   ],
   "source": [
    "print(a, a.shape)\n",
    "print(a.T, a.T.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Array indexing\n",
    "#### Slicing\n",
    "Similar to Python lists, numpy arrays can be sliced by using `start_index:end_index`. You must specify a slice for each dimension of the array. To take all values in a certain dimension, you can use a standalone `:` or just leave that dimension blank. See example below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 3]\n",
      " [6 7]]\n",
      "[[1 2 3 4]\n",
      " [5 6 7 8]]\n",
      "[[1 2 3 4]\n",
      " [5 6 7 8]]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([\n",
    "    [1,2,3,4],\n",
    "    [5,6,7,8],\n",
    "    [9,10,11,12]\n",
    "])\n",
    "# get elements from row 0 to 2 and from column 1 to 3\n",
    "print(a[0:2,1:3])\n",
    "\n",
    "# get elements from row 0 to 2 in all columns\n",
    "print(a[0:2,:])\n",
    "\n",
    "# equivalently, can omit the standalone : as well\n",
    "print(a[0:2,])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A slice of an array is a view into the same data, so modifying it will modify the original array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The original array \n",
      " [[ 1  2  3  4]\n",
      " [ 5  6  7  8]\n",
      " [ 9 10 11 12]]\n",
      "The slice after modifying \n",
      " [[100   3]\n",
      " [  6   7]]\n",
      "The original array after modifying \n",
      " [[  1 100   3   4]\n",
      " [  5   6   7   8]\n",
      " [  9  10  11  12]]\n"
     ]
    }
   ],
   "source": [
    "print(\"The original array \\n\", a)\n",
    "b = a[0:2,1:3]\n",
    "b[0, 0] = 100 # b[0, 0] is in the same place as a[0,1]\n",
    "print(\"The slice after modifying \\n\", b)\n",
    "print(\"The original array after modifying \\n\", a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to get only one element from a certain dimension, you can use integer indexing (which can be mixed with slice indexing in other dimensions). Note that doing this will result in an array of lower rank. For example, let's get the element at column 2 from row 0 to 2 in the following array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3]\n",
      " [7]]\n",
      "[3 7]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([[1,2,3,4], [5,6,7,8], [9,10,11,12]])\n",
    "\n",
    "# using slicing in all dimensions preserves the rank\n",
    "print(a[0:2, 2:3])\n",
    "\n",
    "# each dimension with integer indexing reduces the rank by 1\n",
    "print(a[0:2, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Integer array indexing\n",
    "When you index into numpy arrays using slicing, the resulting array view will always be a subarray of the original array. In contrast, integer array indexing allows you to quickly combine different portions of an input array to form a new output array. For example, given an input matrix `a`, we can form a new matrix with two copies of row 0 in `a` and three copies of row 1 in `a` as follow: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input matrix \n",
      " [[1 2]\n",
      " [3 4]\n",
      " [5 6]]\n",
      "Two copies of row 0, three copies of row 1 \n",
      " [[1 2]\n",
      " [1 2]\n",
      " [3 4]\n",
      " [3 4]\n",
      " [3 4]]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([[1,2], [3, 4], [5, 6]])\n",
    "print(\"The input matrix \\n\", a)\n",
    "print(\"Two copies of row 0, three copies of row 1 \\n\", a[[0, 0, 1, 1, 1],:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One useful trick with integer array indexing is selecting or mutating one element from each dimension of an array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2 12]\n",
      "new array \n",
      " [[  1 102   3]\n",
      " [  4   5   6]\n",
      " [  7   8   9]\n",
      " [ 10  11 112]]\n"
     ]
    }
   ],
   "source": [
    "# original array\n",
    "a = np.array([\n",
    "    [1,2,3],\n",
    "    [4,5,6],\n",
    "    [7,8,9],\n",
    "    [10,11,12]\n",
    "])\n",
    "\n",
    "# an array with two elements: a[0,1] and a[3,2]\n",
    "print(a[[0,3], [1,2]])\n",
    "\n",
    "# increment a[0,1] and a[3,2] by 100 in one line\n",
    "a[[0,3], [1,2]] += 100\n",
    "\n",
    "print(\"new array \\n\", a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Boolean array indexing\n",
    "\n",
    "You can apply a Boolean condition on a Numpy array in the same way you apply it to a single variable. Doing so will apply such condition to every element in the input array, resulting in a new array with the same shape where every element is either `True` or `False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[False False]\n",
      " [ True  True]\n",
      " [ True  True]]\n",
      "[[False False]\n",
      " [ True  True]\n",
      " [False False]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.array([[1,2], [3,4], [5,6]])\n",
    "\n",
    "# True if a[i, j] > 2 and False otherwise\n",
    "print(a > 2)\n",
    "\n",
    "# True if 2 < a[i, j] < 5 and False otherwise\n",
    "print((a > 2) & (a < 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Boolean array can be used as index on an input array `a`, which will return a rank 1 array consisting of the elements in the `a` that correspond to a `True` entry. Note that the return value is always one dimensional, regardless of the rank of `a`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5.23930845 8.44723556 7.50676281 8.64583154]\n"
     ]
    }
   ],
   "source": [
    "# a is 4-dimensional array\n",
    "a = np.random.normal((6,7,8,9))\n",
    "\n",
    "# Boolean array indexing yields 1-dimensional array\n",
    "print(a[a > 0.5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To optimize operations, Numpy provides a set of supported [data types](https://docs.scipy.org/doc/numpy/reference/arrays.dtypes.html). If your array elements do not conform to these data types (e.g., you have a Numpy array of dictionaries), the default data type will be `object` (but why would you want a Numpy array of dictionaries??). Numpy will try to guess the data type of an array upon creation, but you can also explicitly specify the data type, for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int64 float64 int64\n"
     ]
    }
   ],
   "source": [
    "# inferred datatype int\n",
    "x = np.array([0, 1, 2])\n",
    "\n",
    "# inferred datatype float\n",
    "y = np.array([1.5, 2.5])\n",
    "\n",
    "# specified datatype int\n",
    "z = np.array([1, 2], dtype=np.int64)\n",
    "\n",
    "print(x.dtype, y.dtype, z.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also convert between datatypes by using `.astype`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 2.]\n",
      "[1 2]\n",
      "[False  True  True]\n"
     ]
    }
   ],
   "source": [
    "# convert int to float\n",
    "print(x.astype(np.float64))\n",
    "\n",
    "# convert float to int, this involves rounding\n",
    "print(y.astype(np.int64))\n",
    "\n",
    "# equivalent to Boolean array x != 0\n",
    "print(x.astype(np.bool))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Array math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic mathematical functions can be performed elementwise on Numpy arrays. For binary operators, the two input arrays must have the same shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  4]\n",
      " [ 9 16]]\n",
      "[[1.         1.41421356]\n",
      " [1.73205081 2.        ]]\n",
      "[[ 6  8]\n",
      " [10 12]]\n",
      "[[ 5 12]\n",
      " [21 32]]\n",
      "[[0.2        0.33333333]\n",
      " [0.42857143 0.5       ]]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[1,2],[3,4]])\n",
    "y = np.array([[5,6],[7,8]])\n",
    "\n",
    "print(x**2)\n",
    "print(np.sqrt(x))\n",
    "\n",
    "print(x + y)\n",
    "print(x * y)\n",
    "print(x / y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that unlike MATLAB, `*` is elementwise multiplication, not matrix multiplication. We instead use `np.dot` to compute inner products of vectors, to multiply a vector by a matrix, and to multiply matrices. `dot` is available both as a function in the numpy module and as an instance method of array objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n",
      "26\n"
     ]
    }
   ],
   "source": [
    "v = np.array([1, 3])\n",
    "w = np.array([5, 7])\n",
    "\n",
    "# dot product of v and w\n",
    "print(v.dot(w))\n",
    "\n",
    "# equivalent function to compute dot product\n",
    "print(np.dot(v, w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that because `dot(a, b)` can handle most multiplication operations, how it operates depends on what the inputs are (see the [Numpy documentation](https://docs.scipy.org/doc/numpy/reference/generated/numpy.dot.html)). Because of this flexibility, if you don't check our input dimensions carefully, `dot` may perform something unexpected, leading to very subtle bugs. Therefore, in cases where an alternative operator is available:\n",
    "1. if both `a` and `b` are 2-dimensional arrays, `dot` is equivalent to `matmul` or `@`\n",
    "2. if either `a` or `b` is scalar, `dot` is equivalent to `*` (elementwise multiplication),\n",
    "\n",
    "you should use these alternatives instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As another note, recall from Section 1 that 1D arrays in Numpy are always treated as column vectors. Therefore, to perform operations that involve both row and column vectors, we cannot use the typical matrix multiplication operators, but instead need to call the appropriate Numpy function. For example, to compute the outer product $w \\times w^T$, which we expect to be a $2 \\times 2$ matrix, we can use `np.outer`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[25 35]\n",
      " [35 49]]\n",
      "74\n"
     ]
    }
   ],
   "source": [
    "# this will work\n",
    "print(np.outer(w, w))\n",
    "\n",
    "# this will not work because w and w.T are both column vectors\n",
    "# so we only get the dot product instead of a 2x2 matrix\n",
    "print(w @ w.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numpy also provides many useful functions for performing computations on arrays; one of the most useful is sum:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 6]\n",
      "[3 7]\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[1,2],[3,4]])\n",
    "\n",
    "# sum along the columns\n",
    "print(x.sum(axis = 0))\n",
    "\n",
    "# sum along the rows\n",
    "print(x.sum(axis = 1))\n",
    "\n",
    "# sum all elements\n",
    "print(x.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can find the full list of mathematical functions provided by numpy in the [documentation](http://docs.scipy.org/doc/numpy/reference/routines.math.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Broadcasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Broadcasting is a powerful mechanism that allows numpy to work with arrays of different shapes when performing arithmetic operations. Frequently we have a smaller array and a larger array, and we want to use the smaller array multiple times to perform some operation on the larger array.\n",
    "\n",
    "The most simple example is to increment each element in a matrix by a constant:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11 12]\n",
      " [13 14]]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[1,2], [3, 4]])\n",
    "print(x + 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall our earlier note that binary elementwise operation can only be carried out when the two input matrices have the same shape. Here `x` is two-dimensional and `10` is zero-dimensional, so why did `x + 10` work out? The reason is that Numpy automatically turns `10` into a constant matrix that matches the shape of `x` (i.e., `[[10, 10], [10, 10]]`). This process is known as **broadcasting**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can broadcast not only constants but also a lower-rank matrix when it is used together with a higher-rank matrix, for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2  2  4]\n",
      " [ 5  5  7]\n",
      " [ 8  8 10]\n",
      " [11 11 13]]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[1,2,3], [4,5,6], [7,8,9], [10,11,12]])\n",
    "v = np.array([1, 0, 1])\n",
    "# add v to each row of x using broadcasting\n",
    "print(x + v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naturally, the question is: when does broadcasting **not work**? For example, if `a` is a 4x2 matrix and `b` is a 2x1 matrix, would `a + b` work?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (4,2) (2,1) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-379e5dfa5bf9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0ma\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (4,2) (2,1) "
     ]
    }
   ],
   "source": [
    "a = np.ones((4,2))\n",
    "b = np.ones((2,1))\n",
    "a + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it turns out, this does not work. In general, the rule for broadcasting is as follows.\n",
    "\n",
    "1. If `a` and `b` have different ranks, add one-element dimensions to `a` or `b` until they have the same ranks. For example, if `a = [[1,2],[3,4]]` (2-dimensional) and `b = 10` (0-dimensional), we would turn `b` to 2-dimensional, i.e., `[[10]]`.\n",
    "\n",
    "2. Now that `a` and `b` have the same ranks, iterate through each dimension `i` of `a` and `b`:\n",
    "    * If the shapes of `a` and `b` in dimension `i` are the same, move on.\n",
    "    * Else if the shape of `b` is 1 in dimension `i`, copy dimensions `[i, i+1, ...]` of `b` until its shape is the same as that of `a`.\n",
    "    * Else if the shape of `a` is 1 in dimension `i`, copy dimensions `[i, i+1, ...]` of `a` until its shape is the same as that of `b`.\n",
    "    * Else, raise \"ValueError: operands could not be broadcast together\"\n",
    "   \n",
    "For example, `a = [[1,2],[3,4]]` (2-dimensional) and `b = 10` (0-dimensional), broadcasting involves the following steps:\n",
    "\n",
    "1. Turn `b` into 2-dimensional, i.e., `b = [[10]]`, so that it has the same rank as `a`.\n",
    "2. Loop through dimension `i = 0` and `i = 1`:\n",
    "    * With `i = 0, a = [[1,2],[3,4]], b = [[10]]`, we see `a.shape[i] = 2` and `b.shape[i] = 1`. Therefore, we would copy dimension `i+1` of `b`, which is `[10]`, so that `b.shape[i] = 2`, i.e., `b` has two rows. This would turn `b` into `[[10], [10]]`.\n",
    "    * With `i = 1, a = [[1,2],[3,4]], b = [[10], [10]]`, we similarly copy dimension `i+1` of `b`, which is the constant 10, to each row, resulting in `b = [[10, 10], [10, 10]]` as expected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An implication of this rule is that, while we earlier mentioned the typical use case of broadcasting is to operate a \"large\" matrix with a \"small\" matrix, this is not necessarily the case. For example, a matrix of shape (2,1) can be added to a matrix of shape (1,2) through broadcasting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 3],\n",
       "       [3, 4]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([[1], [2]])\n",
    "a + a.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should also note that the matrix manipulations involved in step 1 and 2 of the broadcasting process above can be useful on their own. In particular, adding one-element dimensions to a matrix can be done in array indexing with the use of the keyword `None`, which is equivalent to `np.newaxis` (for more details see the [documentation](https://docs.scipy.org/doc/numpy/reference/arrays.indexing.html)):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "[10]\n",
      "[[10]]\n",
      "[[10]]\n"
     ]
    }
   ],
   "source": [
    "# b is 0D\n",
    "b = np.array(10)\n",
    "print(b)\n",
    "\n",
    "# turn 0D to 1D\n",
    "b_1d = b[None]\n",
    "print(b_1d)\n",
    "\n",
    "# turn 0D to 2D\n",
    "b_2d = b[None, None]\n",
    "print(b_2d)\n",
    "\n",
    "# turn 1D to 2D, note the use of :\n",
    "print(b_1d[:, None])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For outer products on 1D vectors, other than using `np.outer` as we introduced earlier, it is also possible to broadcast the 1D vectors to 2D matrices and multiply them as usual:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5  7]\n",
      " [15 21]]\n",
      "[[ 5  7]\n",
      " [15 21]]\n"
     ]
    }
   ],
   "source": [
    "v = np.array([1, 3])\n",
    "w = np.array([5, 7])\n",
    "\n",
    "print(np.outer(v, w))\n",
    "\n",
    "print(v[:,None] @ w[:,None].T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And copying dimensions can be done with `np.tile`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3],\n",
       "       [1, 2, 3],\n",
       "       [1, 2, 3]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([1, 2, 3])\n",
    "# stack 3 copies of x on top of each other\n",
    "np.tile(x, (3, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Broadcasting typically makes your code more concise and faster, so you should strive to use it where possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This brief overview has touched on many of the important things that you need to know about numpy, but is far from complete. Check out the [numpy reference](https://numpy.org/doc/stable/reference/index.html) to find out much more about numpy.\n",
    "\n",
    "In the next section, we will cover how Numpy can be used for efficient computation of complex procedures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Applications of Numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The primary advantage of Numpy is that, due to its underlying C implementation, array-based operations are much faster than in Python. For example, let's consider the task of summing over all integers from 1 to 10000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10000\n",
    "l = np.arange(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.29 ms ± 197 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "s = 0\n",
    "for item in l:\n",
    "    s += item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.44 µs ± 59.2 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "l.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Noting that $1ms$ = $1000\\mu s$, we see that using Numpy's `sum` function is 350+ times faster than normal Python loop, and this difference is even more prominent for larger input size. Therefore, a rule of thumb for computationally heavy tasks is: **use Numpy whenever possible**! Avoid running computations using Python loops, or on Python lists; if you want to perform any operation over a large dataset, always thinks in terms of matrices.\n",
    "\n",
    "In this section, we will look at how to implement common machine learning procedures using Numpy. The main takeaway is for you to adopt a matrix-based mindset. If you need a linear algebra refresher, take a look at http://www.cs.cmu.edu/~zkolter/course/linalg/. In particular, the three sections about \"Putting Equations into Matrix Form\" are closely related to our materials."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1: Log-likelihood function\n",
    "Given $n$ iid data points $\\{x^{(i)}\\}_{i=1}^n$ from a distribution with pdf / pmf $P$, we define the log-likelihood of the data given the model $\\theta$ as\n",
    "\\begin{equation}\n",
    "    \\boxed{\\mathcal{LL}(\\theta) = \\log p(x^{(1)}, \\ldots, x^{(n)}; \\theta) = \\sum_{i=1}^n \\log P(x^{(i)}; \\theta).}\n",
    "\\end{equation}\n",
    "\n",
    "There are two steps to carry out this computation:\n",
    "1. For each data point $x^{(i)}$, compute $\\log P(x^{(i)}; \\theta)$.\n",
    "2. Sum over all the $\\log P(x^{(i)}; \\theta)$.\n",
    "\n",
    "The \"for each\" part in step 1 seems indicative of a loop, but let's think about how we can get all the $\\log P(x^{(i)}; \\theta)$ **together in one matrix**. Assume the input data is in the matrix form $X \\in \\mathbb{R}^{n \\times d}$. To apply the $\\log P(x)$ function to every row $x$ in $X$, we can use `np.apply_along_axis`, which, as the name suggests, applies an input function to every row or column of a matrix. Then we just sum over the return value in every row by `.sum`. Hence, our implementation is as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def log_likelihood(X, log_p, theta):\n",
    "    # log_p is the log pdf / pmf function of the distribution of X\n",
    "    # axis = 1 means applying along the rows\n",
    "    return np.apply_along_axis(lambda x: log_p(x, theta), 1, X).sum()\n",
    "\n",
    "# example: log likelihood of getting 5 heads from tossing a fair coin 5 times\n",
    "from scipy.stats import bernoulli\n",
    "log_likelihood(np.ones((5,1)), bernoulli.logpmf, 1/2) == np.log(1/(2**5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2: Linear Regression\n",
    "Given input data $X \\in \\mathbb{R}^{n \\times d}$ and output $Y \\in \\mathbb{R}^{n \\times 1}$, linear regression attempts to model the relationship between $X$ and $Y$ by a linear function $h_\\theta(x) = \\theta^Tx$, where $\\theta \\in \\mathbb{R}^{d \\times 1}$. To evaluate the goodness of fit of a particular parameter $\\theta$, we compute the mean squared error\n",
    "$$\\boxed{\\mathcal L(\\theta) = \\frac 1 n \\sum_{i=1}^n (\\theta^T x^{(i)} - y^{(i)})^2}$$\n",
    "\n",
    "To implement this loss function, we should not compute the individual $(\\theta^T x^{(i)} - y^{(i)})^2$ values and add them up, as this requires a loop. Instead, taking advantage of the fact that $X$ and $Y$ are already in matrix format, we can get all the $\\theta^T x^{(i)} - y^{(i)}$ terms **together in one vector**:\n",
    "$$M = X \\theta - Y = [\\theta^T x^{(1)} - y^{(1)}, \\theta^T x^{(2)} - y^{(2)}, \\ldots, \\theta^T x^{(n)} - y^{(n)}]^T$$\n",
    "and then compute the sum of squares of the elements in this matrix simply by `(M**2).sum()` or `np.linalg.norm(M)**2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.6666666666666667"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mse(theta, X, Y):\n",
    "    return ((X @ theta - Y)**2).sum() / X.shape[0]\n",
    "\n",
    "# example: MSE of the line y = 2x w.r.t the dataset {(1, 2), (2, 5), (3, 8)} is 5/3\n",
    "X = np.array([[1], [2], [3]])\n",
    "Y = np.array([2, 5, 8])\n",
    "theta = np.array([2])\n",
    "mse(theta, X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 3: K-means Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-means clustering attempts to assign each data point to one of $k$ clusters $C = \\{0, 1, \\ldots, k-1\\}$ so that the total distance between each data point and its nearest cluster center (i.e., the *within-cluster variance*) is minimized. At a high level, the algorithm has three steps, where step 2 and 3 can be repeated until convergence:\n",
    "\n",
    "1. Initialize the cluster centers $U \\in \\mathbb{R}^{k \\times d}$ randomly.\n",
    "2. Assign each data point $x^{(i)}$ to the cluster whose center is closest to it,\n",
    "$$ y^{(i)} = \\text{argmin}_{c \\in C} \\| \\mu^{(c)} - x^{(i)} \\|_2^2, \\ i = 1, \\ldots, n.$$\n",
    "3. Based on this cluster assignment, recompute the cluster centers:\n",
    "\n",
    "$$\\boxed{\\mu^{(c)} \\leftarrow \\text{Mean}(\\{ x^{(i)} \\mid y^{(i)} = c \\}), \\ c \\in C}$$\n",
    "\n",
    "Given input data $X \\in \\mathbb{R}^{n \\times d}$ and cluster assignments $Y \\in C^{n \\times 1}$, how we can recompute the cluster centers through the conditional sum in step 3? Again, try to resist the temptation to use a for-loop with an inner if-statement to check for $y^{(i)} = c$. Instead, we aim to get all the $\\mu^{(c)}$'s **together in one matrix**.\n",
    "\n",
    "Let's think about a simple example with three 1D data points and two clusters (0 and 1):\n",
    "\n",
    "$$X = \\begin{pmatrix} 1 \\\\ 7 \\\\ 24 \\end{pmatrix}, \\quad Y = \\begin{pmatrix} 0 \\\\ 1 \\\\ 0 \\\\ \\end{pmatrix}.$$\n",
    "\n",
    "In this case, our expected output, which is the matrix of all the new $\\mu^{(c)}$'s, is\n",
    "$$U = \\begin{pmatrix} (x^{(1)} + x^{(3)})/2 \\\\ x^{(2)} \\end{pmatrix} = \\begin{pmatrix} 25/2 \\\\ 7 \\end{pmatrix}.$$\n",
    "\n",
    "Our goal is to multiply $X$ with another matrix $M$ (or multiply $M$ with $X$) that can yield $U$ right away. Note that $X \\in \\mathbb{R}^{3 \\times 1}$ while $U \\in \\mathbb{R}^{2 \\times 1}$, so the only way for this multiplication to work is $M \\in \\mathbb{R}^{2 \\times 3}$ and\n",
    "$$MX = \\begin{pmatrix} ? & ? & ? \\\\ ? & ? & ? \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 7 \\\\ 24 \\end{pmatrix} = U = \\begin{pmatrix} 25/2 \\\\ 7 \\end{pmatrix}.$$\n",
    "It's not too hard to identify one possible $M$ as\n",
    "$$M = \\begin{pmatrix} 1/2 & 0 & 1/2 \\\\ 0 & 1 & 0 \\end{pmatrix}.$$\n",
    "So how does this $M$ relate to $Y$? Note that $M$ seems to have a 0 in each column, which reminds us of the [one-hot encoding representation](https://www.kaggle.com/dansbecker/using-categorical-data-with-one-hot-encoding). Indeed, the one-hot encoding of $Y$ does have a lot of similarity with $M$:\n",
    "$$Y' = Y_{\\text{one hot}} = \\begin{pmatrix} 1 & 0 \\\\ 0 & 1 \\\\ 1 & 0 \\end{pmatrix}, \\quad M^T = \\begin{pmatrix} 1/2 & 0 \\\\ 0 & 1 \\\\ 1/2 & 0 \\end{pmatrix}.$$\n",
    "\n",
    "But where does the denominator 2 come from? Recall that we are taking the cluster mean, and there are two points in cluster 0, so 2 must be the cluster size. More generally, each entry $Y'_{i,j}$ would be turned into $\\frac{Y'_{i,j}}{m_j}$, where $m_j$ is the number of 1s in column $j$, i.e., the count of data points in cluster $j$. In other words, we will normalize each column of $Y'$ to obtain $M^T$.\n",
    "\n",
    "In summary, here are the two steps to compute the cluster centers $U$:\n",
    "1. Convert $Y$ into one-hot encoding form and normalize every column.\n",
    "2. Transpose it and multiply with $X$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[12.5],\n",
       "       [ 7. ]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_cluster_centers(X, Y, k):\n",
    "    M_transpose = np.eye(k)[Y,:]\n",
    "    M_transpose /= np.sum(M_transpose, axis = 0)\n",
    "    return M_transpose.T @ X\n",
    "\n",
    "X = np.array([[1], [7], [24]])\n",
    "Y = [0, 1, 0]\n",
    "get_cluster_centers(X, Y, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the use of integer array indexing to construct $M^T$ from the $k \\times k$ identity matrix. Play around with the above code to make sure you understand what each line of code does!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't worry if you are not familiar with the above machine learning concepts, you will learn more about them in 10-601! The skill that you should develop from this tutorial is to efficiently implement any math formula or algorithm by utilizing Numpy. The basic idea is that any time you need to compute a set of vectors, think about getting all of them **together in one matrix** via Numpy matrix operations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Sparse matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we briefly introduce a useful data structure for Project 1 called *sparse matrix*. These are matrices which contain mostly zero entries and only a few non-zero entries (e.g., adjacency matrices from real-world graphs). Storing all these zeroes in a standard matrix format can be a huge waste of computation and memory. Scipy provides a [sparse matrix library](https://docs.scipy.org/doc/scipy/reference/sparse.html) that specializes in handling this kind of data. An important advantage of Scipy's sparse matrix is that it consumes a lot less memory while being funtionally similar to standard Numpy matrices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Creating sparse matrix\n",
    "The standard way to create a sparse matrix is to simply specify the value, row index and column index of every non-zero entry. For example, in the following matrix\n",
    "$$A = \\begin{pmatrix}\n",
    "    0 & 0 & 3 & 0 \\\\\n",
    "    2 & 0 & 0 & 1 \\\\\n",
    "    0 & 1 & 0 & 0 \\\\\n",
    "    4 & 0 & 1 & 0 \n",
    "\\end{pmatrix}$$\n",
    "we can construct three lists `data, row, col` to store the locations and values of the 6 non-zero entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 3 0]\n",
      " [2 0 0 1]\n",
      " [0 1 0 0]\n",
      " [4 0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "import scipy.sparse as sp\n",
    "data = [2, 4, 1, 3, 1, 1]\n",
    "row = [1, 3, 2, 0, 3, 1]\n",
    "col = [0, 0, 1, 2, 2, 3]\n",
    "\n",
    "m = sp.coo_matrix((data, (row, col)), shape = (4, 4))\n",
    "# .A converts the sparse matrix to its dense representation (of type np.ndarray)\n",
    "print(m.A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that while `coo_matrix` can also take a dense matrix and convert it to sparse, in practice it is better to avoid the creation of any dense matrix altogether and construct the three lists `data, row, col` as input to `coo_matrix` instead. Similarly, `.A` is useful for printing the dense representation, but actual matrix operations should be performed on the sparse object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depending on whether the target matrix operation requires row or column access, a `coo_matrix` object can be converted to either a `csr_matrix` (**compressed sparse row**) or `csc_matrix` (**compressed sparse column**) object. This conversion is necessary, as `coo_matrix` is slow in row and column access, but the conversion process is very fast so don't hesitate to do it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row at index 2:\n",
      "[[0 1 0 0]]\n",
      "column at index 2:\n",
      "[[3]\n",
      " [0]\n",
      " [0]\n",
      " [1]]\n"
     ]
    }
   ],
   "source": [
    "# CSR matrix allows for fast row access\n",
    "m_rows = m.tocsr()\n",
    "print(\"row at index 2:\")\n",
    "print(m_rows.getrow(2).A)\n",
    "\n",
    "# CSC matrix allows for fast column access\n",
    "m_cols = m.tocsc()\n",
    "print(\"column at index 2:\")\n",
    "print(m_cols.getcol(2).A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that in the above cases, the returned row and column are both **2D sparse matrices**, not 1D vectors like what Numpy would return. If our expected output is 1D vector, we can convert the sparse row / column to dense format and then flatten it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 0]\n",
      "[3 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "print(m_rows.getrow(2).A.ravel())\n",
    "print(m_cols.getcol(2).A.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per the Scipy documentation, the pros and cons of CSR / CSC format are as follows:\n",
    "\n",
    "|  \t| Pros \t| Cons \t|  \t|\n",
    "|-----\t|-------------------------------------------------------------------------------------------------------------------------------------\t|-----------------------------------------------------------------------------------------------\t|---\t|\n",
    "| CSR \t| Efficient arithmetic operations CSR + CSR, CSR * CSR, etc. <br>Efficient row slicing <br>Fast matrix vector products \t| Slow column slicing operations (consider CSC) <br>Changes to the sparsity structure are expensive \t|  \t|\n",
    "| CSC \t| Efficient arithmetic operations CSC + CSC, CSC * CSC, etc. <br>Efficient column slicing <br>Fast matrix vector products (CSR may be faster) \t| Slow row slicing operations (consider CSR) <br>Changes to the sparsity structure are expensive \t|  \t|\n",
    "|  \t|  \t|  \t|  \t|\n",
    "\n",
    "Therefore, after constructing a sparse matrix in `coo_matrix` format, we should think about what kind of operations we need to perform and choose the appropriate conversion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Operating on sparse matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consult the API for [CSR matrix](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.csr_matrix.html#scipy.sparse.csr_matrix) and [CSC matrix](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.csc_matrix.html#scipy.sparse.csc_matrix) for their supported operations. In general, standard mathematical transformations (e.g., `power, sqrt, sum`), as well as matrix operations (`dot, multiply, transpose`) are available.\n",
    "\n",
    "Consider for example the speedup in matrix-vector multiplication when using the sparse matrix format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identity matrix in sparse format\n",
    "A = sp.eye(1000)\n",
    "\n",
    "# identity matrix in standard Numpy format\n",
    "B = np.eye(1000)\n",
    "\n",
    "# vector to multiply with\n",
    "x = np.random.randn(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.12 µs ± 167 ns per loop (mean ± std. dev. of 7 runs, 100000 loops each)\n",
      "168 µs ± 4.4 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit A.dot(x)\n",
    "%timeit B.dot(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see a 28x increase in speed, though the speedup will increase with sparsity relative to the dense matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An important point to keep in mind when working with sparse matrix is that, if an operation is supported by both `scipy.sparse` and `numpy`, **always use the scipy.sparse version**. Sometimes the `numpy` version will convert the sparse matrix input to dense matrix, which makes our sparse representation pointless. For example, if we use `np.dot(A, x)` instead of `A.dot(x)`, the time taken suddenly increases by a factor of 4500 (because of the sparse to dense conversion time)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27.2 ms ± 378 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit np.dot(A, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Escalation meme](https://i.kym-cdn.com/photos/images/newsfeed/000/353/279/e31.jpg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
